Part 01

1) 이론을 세우는 데 기초가 되는 사실이나 자료를 말하며 컴퓨터 시대에는 프로그램을 운용할 수 있는 형태로 기호화 숫자화한 자료를 말한다.

2) 정보는 필요한 시기에 전달된 데이터를 말한다.

3) 빅데이터는 통상적으로 사용되는 데이터 수집, 관리 및 처리 소프트웨어의 수용 한계를 넘어서는 크기의 데이터를 말한다(위키백과, 맥킨지 2011). 
가트너 그룹의 더그 레이니(Doug Raney)는 2011년 빅데이터를 3V 모델로 정의했다.
- 데이터의 양(Volumn), 데이터 입출력 속도(Velocity), 데이터 다양성(Variety))
IBM은 3V에 정확성(Veracity)을 추가하여 4V로 정의한다. 이외에 가변성(Variability)을 추가하여 4V로 정의하는 경우도 있다.

4) 데이터로부터 의미 있는 정보를 추출하는 학문이다. 데이터의 구체적인 내용이 아닌 서로 다른 성질의 내용이나 형식의 데이터에 공통으로 존재하는 성질 또는 그것을 다루기 위한 기술의 개발에 중점을 둔다(위키백과).
사용하는 기술은 수학, 통계학, 정보 공학, 패턴 인식, 기계 학습, 데이터 마이닝, 데이터베이스 등이 있다.

5) 문제의 정의 및 문제를 작은 단위로 분할
분할된 문제에 맞추어 데이터를 조정하여 분석 수행
분석가의 가정을 명시적으로 밝히고 데이터에 근거한 결론 도출
새로운 상황이 발생하면 위의 과정 반복

6) 34쪽 그림 참고

7) 
- KDD 분석 방법론 : 프로 파일링을 기반으로 데이터베이스로부터 통계적 패턴이나 지식을 찾기 위한 방법을 체계적으로 정리한 것
- CRISP-DM 분석 방법론 : 각 단계가 피드백에 의해 완성도를 높일 수 있도록 구성되어 있다.
- 빅데이터 분석 방법론 : 빅데이터를 분석하기 위한 방법론은 계층적 프로세스 모델의 형태를 가지며, 3계층으로 구성된다. 3계층은 단계(Phase)-태스크(Task)-스텝(Step)으로 구성된다.

8) 
- 하향식 접근 방법(Top-Down Approach) : 문제가 주어지고, 이에 대한 해답을 구하기 위하여 여러 과정을 단계별로 수행하는 방식
- 상향식 접근 방법(Botton-Up Approach) : 문제를 정의하기 어려운 경우에 데이터를 바탕으로 문제를 정의하고 해결 방안을 찾는 과정을 반복하여 지속적으로 개선하는 방식

9) 
과제명 
과제 중 분석할 것(분석명) 및 분석의 상세 내용(분석 정의)
소스 데이터
분석 방법
데이터 입수 및 분석의 난이도
분석 수행 주기
분석 결과에 대한 검증 주체
상세 분석 과정 정리

10) 40쪽 그림 참고

==============================

Part 02

1) 
* R 콘솔 창 폰트를 변경할 수 있다.
- R을 설치한 디렉터리에서 etc/Rconsole 파일을 연다.
- 파일 내용 중에서 font와 points를 변경하면, 폰트와 크기가 변경된다.
(예) fonts = TT Courier New --> fonts = TT MS Gothic으로 바꾼다.
points = 20  --> points = 12로 바꾼다.

* R을 MDI에서 운영하고 싶지 않다. 
- R을 설치한 디렉터리에서 etc/Rconsole 파일을 연다.
- MDI=no 앞에 있는 #을 삭제한다.

2) 
-  대화형 모드 : 실시간으로 명령을 입력하고 결과를 출력하는 방식
-  배치형 모드 : 수행할 명령을 별도의 파일로 만들고 일괄 수행하는 방식

3)
-  사용하는 변수나 데이터를 저장하고 읽어오는 경우 : save, load
-  데이터를 CSV 형태로 만들고 저장하고, 읽어오는 경우 : write.csv,  read.csv
-  일반 텍스트 파일을 읽어오는 경우 : scan, read.table
-  그 외 excel 파일을 읽어오는 경우 등 다양한 명령어가 있다.

4) 60쪽 표 참고

5) 
> Function1 <- function() {  // 함수 Function1을 선언한다. 
+    x <- 10
+    y <- 20
+    result <- x+y
+    return(result)  // 함수가 result를 돌려 준다.
+ }
> Function1()  // 위에서 선언한 함수를 사용한다.
[1] 30

이외에도 배치 파일 형태로 만들어서 필요할 때 수행할 수도 있다(save, load).

6) 
- if (조건) 명령문
- if (조건) 명령문1  else 명령문2
- ifelse (조건, 명령문1, 명령문2)
- switch (기준, 조건1, 명령문1, 조건2, 명령문2 .....)
- for (반목) 명령문
- while (조건) 명령문
- repeat 명령문

7) 벡터형의 데이터를 column, row를 기준으로 합쳐서 행렬형의 데이터를 만들 때 사용

8)    
-  summary : 기본 통계량을 확인한다.
-  oirder : 데이터를 정렬한다.
-  sample : 난수를 생성한다.

9) 
-  split : 데이터를 분리한다.
-  subset : 데이터에서 소규모 데이터를 생성한다.
-  with : 복잡한 명령어에서 데이터의 이름을 명시하지 않아도 되게 한다.
-  merge : 데이터를 합친다.

10) dplyr을 포함한 여러 명령어를 이어서 수행하도록 한다.

11) 데이터의 조작에 SQL문을 사용할 수 있게 한다.

==============================

Part 03

1) 
-  데이터에 대한 이해
-  통계 및 분석 방법에 대한 이해
-  분석 도구에 대한 이해
-  비즈니스 커뮤니케이션

2) 
-  서술적 분석(Descriptive Analysis)
-  탐구적 분석(Exploratory Analysis)
-  추정 분석(Inferential Analysis)
-  예측 분석(Predictive Analysis)
-  인과 분석(Casual Analysis) 
-  기계론적 분석(Mechanistic Analysis)

3)
-  데이터를 탐색하는 과정
-  특정 컬럼에 대한 정보를 파악하는 과정
-  데이터가 특정 분류에 대한 분포가 어떤지를 파악하는 과정

4) 
- 데이터 확인
- 데이터 형식의 변경
- 결측값 처리
- 이상값 처리
- Feature Engineering 

5) 
- 삭제(Deletion)
- 다른값으로 대체(Replacement)
- 예측값 삽입(Insert)

6) 
-  단순 삭제
-  다른 값으로 대체
-  변수화
-  리샘플링
-  케이스를 분리하여 분석

7) 데이터의 모양을 정규화함으로써 분석의 결과가 좀 더 정교해진다.

8) 데이터에 변수가 많은 경우 변수의 개수를 줄이기 위함이다.

9) 
-  0에 가까운 분산을 가지는 변수를 제거
-  상관관계가 높은 변수를 제거

10) 카이 제곱 검정을 통한 중요 변수의 선발

==============================

Part 04

1) 데이터 시각화는 데이터를 그래프로 표현하는 것을 말한다. 데이터를 그래프로 표현하는 것은 데이터에 대한 분석을 목적으로 하는 경우와 고객에게 전달하고자 하는 것을 정리하는 두 가지의 용도를 가진다. 
데이터 시각화는 '데이터를 보여 주고', '적절한 비교를 하고', '연관된 여러 변수를 보여 준다'는 세 가지 조건을 만족해야 한다.

2) 148쪽 참고

3) split.screen,  par/mfrow

4) 155쪽 표 참고

5) 점, 막대, 히스토그램, 파이, 상자 그래프

6) 꺾은선, 선분, 화살표, 사각형, 문자열, 직선을 기존 그림에 추가할 수 있다.

7) 
-  점, 막대, 히스토그램, 파이, 상자 그래프이다.
-  꺾은선, 선분, 화살표, 사각형, 문자열, 직선을 기존 그림에 추가할 수 있다.
-  sunflower, stars persp, contour
184쪽 표 참고

8) ggplot2, lattice

9) 
-  데이터 준비
-  기본 그래프 그리기
-  그래프 다듬기(size, shape, color, stroke)
-  주석 달기(aes)
-  Title, x, y축의 명칭 설정 및 색이나 폰트 결정, 그리고 크기의 설정
-  필요한 색상이나 축의 변경
-  그래프 추가

10) 별도의 해설은 없다.

11) 별도의 해설은 없다.

==============================

Part 05

1) 샘플을 통해 모집단을 예측하는 것이다.

2) 
* 범주형 데이터(Categorical Data) : 사전에 정해진 특정 유형으로 분류되는 데이터
- 명목형 : 분류된 데이터 사이 비교가 불가능한 경우 (예) 성별, 좌파/우파...
- 순서형 : 분류된 데이터 사이 순서가 가능한 경우 (예) 대/중/소, 수/우/미/양/가...
* 연속형 데이터(Continuous Data) : 정량적으로 표현된 데이터
- 등간척도 : 온도, 시간 등의 데이터

3)
- 어떤 그룹, 집단, 형태 등이 차이가 있다고 볼 수 있는지를 알아보는 것 = 차이 검정
(예) 샘플로 뽑은 데이터가 전체 모집단을 대표한다고 볼 수 있는지를 검정한다.
만약 대표한다면, 샘플에서 얻은 데이터로 모집단을 예측할 수 있다.
(예) 약을 먹기 전과 후의 환자의 상태를 조사한 후에, 이것이 차이가 있는지를 검정한다. 이것을 통하여 약이 효과가 있는지 없는지를 알 수 있다.
- 어떤 그룹 사이 인과관계(상관관계)가 있는지를 알아보는 것 = 인과 관계
(예) 두 그룹의 데이터가 상관관계가 있는지를 알아보는 것이다. 상관관계가 있다면
한쪽의 변화에 대하여 다른 쪽의 변화를 예측할 수 있다. 상관관계가 어느 정도인지 
보여주는 것인 상관계수이고, 이것을 얻고, 분석하는 것이 상관분석이다. 
회귀분석도 상관관계와 관련이 있다.

4) 
- 단순 및 가중치를 부여한 표본 추출
- 층화임의 추출
- 층화암의 추출 중 Systematic을 사용하는 경우

5) 
- 데이터 사이 상호 연관이 있는지를 검정하는 것
- 카이 제곱 검정, 피셔 검정

6) 차이가 있는지를 확인할 수 있다.

7) 
-  두 데이터가 같은 분포를 하는지 또는 정규 분포인지를 검정한다.
-  콜모고로프-스미노프 검정, 샤피로 윌크 검정

8) 두 데이터가 같은 분포를 하는지, 정규분포를 하는지를 확인할 수 있다.

9) 
차이 검정 : 하나, 두개 또는 그 이상의 데이터가 상호 또는 모집단과 비교하여 차이가 있다고 볼 수 있는지를 검정하는 것이다.
인과 관계 : 원인과 결과 간의 관계를 밝혀서 그 결과로 발생하는 현상을 설명하는 것이다. 

10) 
- t-test : 하나 혹은 두 개의 데이터를 대상으로 한다
- ANOVA : 두 개 이상의 데이터를 대상으로 한다.
- 부호 검정(Sign Test) : 특수 형태의 데이터에 적용한다.
- 비율 검정(Proportions Test, Prop Test) : 특수 형태의 데이터에 적용한다.

11) 두 변수 사이의 관련성을 파악하는 것이다.

==============================

Part 06

1) 통계는 필요한 데이터를 실험 계획법이나 샘플링을 이용해 수집하지만, 데이터마이닝은 비계획적으로 수집된 데이터를 분석 자료로 사용한다. 그러므로 데이터마이닝은 데이터의 정제가 필요한 경우가 많다.
유사하게 빅데이터는 자연스럽게 발생한 데이터를 분석 자료로 사용하는 경우라고 할 수 있다. 예를 들어, IoT 장비에서 발생하는 데이터, 스마트폰에서 발생하는 데이터 등이 빅데이터의 대표적인 경우이다.
통계는 샘플을 통한 모집단의 추정, 검정이 주 관심이지만, 데이터마이닝은 분석하려는 데이터 자체가 모집단이다. 빅데이터도 데이터 마이닝과 같다.
데이터 마이닝은 미래에 대한 예측을 중시하지만, 통계는 추정과 검정을 중시한다. 빅데이터는 데이터가 다른 뿐, 데이터 마이닝과 목적이 같다.

2) 대용량의 자료로부터 정보의 요약과 미래에 대한 예측을 목표로하여 자료에 존재하는 관계, 패턴, 규칙 등을 탐색하고, 이를 통계적으로 모형화함으로써 이전에는 알려지지 않은 유용한 지식을 추출하는 일련의 과정이다.

3)  
* 지도 학습(Supervised Learning)과 분석 방법
자료가 입력 변수(Input Variable)와 출력 변수(Output Variable)로 주어지면 출력 변수와 입력 변수의 함수적 의존 관계를 자료로부터 추정함으로써 예측 모형을 얻은 것

* 지도 학습에 속하는 분석 방법
- 회귀 분석(Regression Analysis)  
- 선형 회귀 분석 : 입력과 출력 변수 사이 관계가 선형이라는 가정이 들어간 것
- 비선형 회귀 분석 : 입력과 출력 변수간의 관계가 비선형이라는 가정이 들어간 것을 
말한다. 신경망모델과 커널 방법론이 여기에 속한다고 볼 수 있다.
- 로지스틱 회귀 : 출력변수가 범주형인 경우에 적용하는 회귀 분석 기법. 범주형이 0/1인 경우 로지스틱 회귀라고 하고, 0/1/2/3/... 인 경우 다항 로지스틱 회귀라고 한다.
- 의사 결정론(Decision Analysis) : 선 형회귀, 로지스틱 회귀 등을 이용한 의사 결정 지원 방법을 말한다. 판별 분석이 여기에 속하는 분석 방법이다.
- 의사 결정 나무(Decision Tree)
- 신경망(Neural Network)
- 커널 방법론(Kernel Methods) : 회귀 함수, 베이스 분류 함수의 비선형 모델을 말한다. 
- 앙상블(Ensemble) : 주어진 지료로 여러 예측 모형을 만들고, 이를 결합하여 최종 예측 모형을 만드는 방법을 말한다.
- 서포트 벡터 기계(Support Vector Machine) : 예측이 정확하고 모형이 유연하여 다양한 자료에 적용할 수 있어서 여러 예측 문제에 적용된다.

* 자율 학습 또는 비지도 학습과 분석 방법
출력 변수가 없이 입력 변수만 주어진 경우에, 입력 변수들 사이 상호관계나 입력 자료값들 간의 관계에 대하여 탐색적으로 분석하는 것을 말한다.
- 자원 축소 기법(Dimension Reduction)
주성분 분석(Principle Component Analysis), 인자 분석(Factor Analysis), 독립 성분 분석, 다차원 척도법
- 연관 규칙 분석(Association Rule Analysis)
- 군집 분석(Cluster Analysis)

4) 
-  회귀 분석, 로지스틱 회귀
-  의사 결정 트리, 앙상블
-  군집 분석
-  주성분 분석
-  인자 분석
-  연관 규칙 분석
-  시계열 분석
-  구조 방정식

5) 
- SAS의 Enterprise Miner
- SPSS의 Clementine
- IBM의 Intelligent Miner
- Oracle의 Darwin
- Salford의 CART&MARS
- R 

==============================

Part 07 

1) 회귀 모델은 데이터 마이닝의 지도 학습에 속하는 기법으로 입력과 출력 데이터 사이 함수적 의존 관계를 추정함으로써 미래를 예측하는 것이다.

2) 신경망으로 예측을 하는 경우에 예측의 정확도에 영향을 미치는 요인은 몇 개의 층을 쌓느냐와 함수의 설정값(decay)이 얼마인지이다.

3) 회귀 분석은 두 변수(독립 변수:x, 종속 변수:y)의 관계를 선형으로 표현하고 이것을 이용하여 미래를 예측하였다. 그런데, 종속 변수(y)가 0과1, 합격/불합격같은 이산형 변수인 경우에는 어떻게 처리하는지가 어렵다. 그래서 개발된 방법이 로지스틱 회귀이다. 

4) 중선형 회귀(다중 선형 회귀)는 독립 변수가 두 개 이상인 회귀 분석을 말한다. 즉, 종속 변수 y에 영향을 미치는 변수가 두 개 이상인 경우에 사용하는 방법이다.

5) 주어진 데이터의 독립 변수(x)와 종속 변수(y) 사이의 관계가 선형이라는 가정은 회귀 함수에서 기본적으로 사용하고 있다. 이런 가정은 모델의 구성과 계산에서 간편하기 때문에 많이 사용된다. 그런데, 특수한 경우에는 선형이라는 가정이 맞지 않는 경우가 발생한다. 이런 상황을 대비하여 비선형 모형화 기법이 개발되었다.
커널 방법론(Kernet Methods)은 대표적인 비선형 모형화 기법으로 국소 선형 회귀(Kernel Smoothing: Local Linear Regression)을 사용한다. 간단히 말해서 근처에 있는 점들의 위치를 고려해서 종속 변수(y)의 좌표를 조정하는 것이라고 할 수 있다.

6) 종속 변수가 0, 1이면 로지스틱 회귀, 0, 1, 2, 3 등 여러 종류이면 다항 로지스틱 회귀를 사용한다.

==============================

Part 08

1) 자료가 입력 변수와 출력 변수로 주어지고, 출력 변수와 입력 변수 사이 함수적 의존 관계를 자료로부터 학습을 통해 추정함으로써 미래를 예측할 수 있는 모형을 얻는 것을 말한다.

2) 
- CART(Classification and Regression Tree) : 가장 많이 사용하는 알고리즘이다. 
- C4.5와 C5.0 : CART와는 다르게 각 마디에서 다지 분리(Multiple Split)가 가능하다.
- CHAID(Chi-squared Automatic Interaction Detection) : 범주형 변수에 적용한다.

3) 
- CART 알고리즘 ? rpart 패키지의 rpart
- 조건부 추론나무 ? rpart 패키지의 ctree

4) 스팸 메일의 제거를 포함한 조건 검색 분야

5) 앙상블은 주어진 자료로부터 여러 개의 예측 모형을 만든 후, 이것을 결합하여 하나의 최종적인 예측 모형을 만드는 방법을 통칭하는 것이다. 앙상블 기법 중에서 최초로 제안된 것은 Breiman(1996)의 배깅(Bagging)이다. 이후에 부스팅(Boosting)이 도입되고 랜덤 포레스트(Random Forest)가 개발되었다.

6) 
- 배깅 : party, caret 패키지, ctree, dataframe, funcResultValue 
- 랜덤 포레스트 : randomForest 패키지, randomForest 명령어

7) caret 패키지, e1071 패키지,  tune.svm, svm 명령어

8) 베이지안 방법론은 베이즈 확률 이론을 적용한 예측 모델이다. 베이지언 확률 모델은 전통 통계학의 빈도 주의와 함께 현대 통계학의 중요한 축이다.

9) e1071 패키지, naiveBayer 명령어

==============================

Part 09

1) 군집 분석은 데이터를 구성하는 각 개체의 유사성을 측정하여, 상호 유사성이 높은 대상을 집단으로 분류하고, 군집에 속한 개체들의 유사성과 서로 다른 군집에 속한 개체간의 상이성을 파악하는 분석 방법이다.

2) 
* 분할적 군집(Partitional Clustering) : 특정 점을 기준으로 가까운 것끼리 묶는 것
- k 평균 군집법(k-means Clustering)
- The k-Medoids 군집법(The k-Medoids Clustering)
- 계층적 군집법(Hierarchical Clustering)

* 계층적 군집(Hierarchical Clustering) : 트리 구조처럼 분리하는 것
- 밀도 기반 군집법(Density Based Clustering)

3)  많은 변수로 구성된 데이터에 대하여 주성분이라는 새로운 변수를 생성하여 기존 변수들보다 차원을 축소하여 분석을 수행하는 방법을 말한다.

4) 여러 개의 서로 관련이 있는 변수들로 구성된 데이터에서, 이 변수를 설명할 수 있는 새로운 공통 변수를 파악하는 통계적 분석 방법을 말한다.

5) 
- 공통점 : 데이터를 구성하는 여러 개의 변수로부터 적은 수의 새로운 변수를 생성하는 것이다.
- 차이점 : 주성분 분석은 각 변수들이 중요성이 있다. 즉, 제1주성분, 제2주성분 등으로 구분되지만, 인자 분석은 변수들이 기본적으로 대등한 관계를 가진다.

6) 독립 성분 분석은 섞여있는 데이터에서 특정 데이터를 뽑는 기법이다. 혼재된 데이터에서 특정 성분을 뽑는 경우에 유용하게 사용되는 기법이다. 영상 신호나 안구 움직임등에 대한 분석 등 다양한 분야에서 활용되고 있다.

7) 다차원 척도법은 여러 대상의 특징 사이 관계에 대한 수치적 자료를 이용해서, 유사성에 대한 측정치를 상대적 거리로 구조화하는 방법이다. 따라서 다차원 척도법은 2차원 혹은 3차원에서의 특정 위치에 관측치를 배치해서 보기 쉽게 척도화하는 방법을 말한다.

8) 다차원 척도법은 주어진 데이터를 기반으로 수행하는 또 다른 관점의 군집 분석이라고 할 수 있다. 주어진 데이터를 대상으로 특정 기준(거리, 동일성)에 의거 재배열한 후에 그래프로 표현해서 분석가가 주어진 데이터를 특징에 따른 군집으로 분류할 수 있다. 이를 통하여 분리된 군집을 대상으로 또다른 분석 기법을 적용할 수도 있고, 이 자체로서 분석을 마치고 대응 방안을 찾을 수도 있다.

==============================

Part 10

1) 대용량 데이터베이스에서 변수들 사이 흥미로운 관계를 탐색하기 위해 고안된 방법이다. 마케팅과 웹 마이닝등에서 많이 사용된다.
연관 규칙 분석은 자료에 존재하는 항목들 사이 if~then 형식의 연관 규칙을 찾는 방법으로서 자율 학습법의 하나이다.

2) 앞의 예에서 보여준 그림을 통해서 아래의 결과를 읽을 수 있음을 확인한다.
-  a, b 물건을 산 사람은 d 물건을 샀다.
-  b, e 물건을 산 사람은 d, a 물건을 샀다.
-  a, e 물건을 산 사람은 d, b 물건을 샀다.

3) 두 개 이상의 모집단으로부터 표본이 섞였을 때, 개별 경우에 대하여 그것이 어떤 모집단에 속하는지를 판별하기 위한 함수를 만들어서 데이터를 분류하는 방법이다.

4) 로지스틱회귀와 유사하다. 

5) 시계열은 일정시간 간격으로 관측된 데이터의 수열을 말한다. 예로써, 한달동안 공장에서 생산된 일일 생산량, 지난 20년간 목동지역의 단위 인구 수 등을 말한다.
시계열 분석은 시계열 데이터를 해석하고 이해하는데 쓰이는 여러 방법을 말한다. 시계열 분석은 시간을 주기로 가지는 데이터를 기반으로 데이터의 흐름, 중요 요인, 미래 변동 예측을 수행하는 데 사용한다.

6) 
* 1단계 (분해 단계) : 시계열 자료를 시각화해서 특성을 파악한다.
* 2단계 (변환 단계) : 시계열 자료를 안정적 시계열로 변환한다.
   <안정적 시계열의 특징>
- 시간의 추이와 관계없이 평균이 불변
- 시간의 추이와 관계없이 분산이 불변
- 두 시점간의 공분산이 기준 시점과 무관   
*  3단계 (파라미터 결정) : ACF/PACF 차트나 auto.arima 함수를 이용하여 최적화된 파라미터를 찾는다.
*  4단계 (모형만들기) : ARIMA 모형을 구성한다.
*  5단계 (예측하기) : 미래 추이를 예측한다.

7) 
- 자기 상관 모델(AR Model, Autocorrelation Model) : 어떤 변수에 대해서 이전 값이 이후 값에 영향을 미치는 경우에 적용하는 모델이다. 검사를 위하여 PACF를 사용한다.   
(예) 용수철의 움직임

- 이동 평균 모델(MA Model, Moving Average Model) : 시간이 지나면서 어떤 변수의 평균 값이 지속적으로 감소하거나 증가하는 경향이 있는 경우에 적용하는 모델이다. 검사를 위하여 ACF를 사용한다.
   (예) 가정의 전기 사용량

- ARMA 모델(Autoregressive Moving Average Model) : AR + MA 모델이다.

- ARIMA 모델(Autoregressive Integrated Moving Average Model) : ARMA 모델이 과거의 데이터를 사용하는 것에 비해서 ARIMA 모델은 과거의 데이터가 가지는 추세(Momentum)도 반영하는 것이다. 특히, 데이터가 비안정적(Non Stationary Series)인 경우에도 안정화 과정을 거쳐서 적용이 가능하다.

==============================

Part 11

1) 워드 클라우드 기법은 텍스트로 된 데이터에서 가장 빈번하게 사용되는 단어를 선별하는 기법이다. 웹상의 데이터 분석 기법 중의 하나로서 텍스트 마이닝(Text Mining)이라고도 한다. 

2) 401쪽 표 참고

3) 개인적인 인간 관계가 확산되어 형성된 사람들 사이의 네트워크인 사회 연결망(Social        Network)을 분석하는 것을 소셜 네트워크 분석(Social Network Analysis)이라고 한다.

4) 
- 카이젠(Kxen) : 인피니트 인사이트 소프트웨어는 분류, 회귀, 시계열, 제품 추천 및 소셜 네트워크 분석에 사용된다.
- 에스에이에스(SAS; Statistical Analysis System) : SAS 제품에 소셜 네트워크 분석 기능이 있다.
- 엑스트랙(XTRACT) : 소셜 네트워크, 고객 프로 파일링 등의 기능을 제공한다.
- 이디로(IDIRO) : 소셜 네트워크 및 빅데이터 분석 기능을 제공한다.
- 파젝(Pajek) : 대학에서 만든 네트워크 분석 소프트웨어이다.
- 인플로우(InFlow) : 소셜 네트워크 분석과 시각화 기능을 제공한다.
- NodeXL : 엑셀에서 수행되는 소셜 네트워크 분석 프로그램이다.

5) 변수들 사이 직접 또는 간접으로 함수적 관계를 가지는 경로의 모형을 방정식 또는 그림으로 표시해 가설화하고, 그 모형을 수집된 자료에 합치시킴으로써 경로들이 나타내는 연구 가설들을 검증하는 방법을 말한다.
경로 분석은 구조 방정식 모형의 가장 초보적인 형태이다. 그리고 경로 분석의 형태를 도식화 한 것이 경로 도형이다.

6) 417쪽 표 참고
